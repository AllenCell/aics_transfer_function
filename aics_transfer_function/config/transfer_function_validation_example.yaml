# basic parameters
verbose   : False           # 'if specified, print debug information before running
debug     : False           # whether to use debug mode

datapath:
  source        : /allen/aics/assay-dev/users/Jianxu/data/TF_demo_test/source/
  target        : /allen/aics/assay-dev/users/Jianxu/data/TF_demo_test/target/
  prediction    : /allen/aics/assay-dev/users/Jianxu/data/TF_demo_test/prediction/

normalization:
  source:
    method: simple_norm
    params: ("middle_otsu", 3.0, 14.5)
  target:
    method: simple_norm
    params: ("middle_otsu", 1.5, 14.0)

load_trained_model:
  path        : /allen/aics/assay-dev/computational/data/transfer_function_production/hipsc_h2b/models/h2b_20to100_fe06_1022_2128/checkpoints/
  epoch       : latest # which epoch to load? set to latest to use latest cached model
  load_iter   : -1             # which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]

network:
  model       : pix2pix        # chooses which model to use, only "pix2pix" for now.
  netD        : n_layers       # 'specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator')
  netG        : unet_256       # 'specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]')
  input_nc    : 1              # 'number of input image channels: 3 for RGB and 1 for grayscale')
  output_nc   : 1              # 'number of output image channels: 3 for RGB and 1 for grayscale')
  ngf         : 96             # number of gen filters in the last conv layer')
  ndf         : 64             # number of discrim filters in the first conv layer')
  n_layers_D  : 3              # 'only used if netD==n_layers'
  no_dropout  : False          # 'no dropout for the generator'
  norm        : batch          # 'instance normalization or batch normalization [instance | batch]'
  gan_mode    : vanilla        # the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.')
  init_type   : normal         # 'network initialization [normal | xavier | kaiming | orthogonal]'
  init_gain   : 0.02           # 'scaling factor for normal, xavier and orthogonal.'
  input_patch_size  : [32,256,256]  # patch size (z_depth,y_height,x_width)
  batch_size        : 1       # number of images training simultaneously in one iteration, 1 is preferred as default

